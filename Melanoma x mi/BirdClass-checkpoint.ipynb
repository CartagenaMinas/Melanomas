{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"BirdClass-checkpoint.ipynb","provenance":[]},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6BjPHrKq1gVt"},"source":["# Clasificador de imágenes"]},{"cell_type":"code","metadata":{"id":"syGACcPB1yTg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5LRGNfIn1gVz"},"source":["from keras.models import Sequential, Model\n","from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint\n","from keras.utils import np_utils\n","import os\n","import numpy as np\n","from keras.preprocessing import image\n","from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing.image import ImageDataGenerator \n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w1HV-bs81gV6"},"source":["# Configuración de parámetros"]},{"cell_type":"code","metadata":{"id":"0MXr3qNO1gV8"},"source":["width_shape = 224\n","height_shape = 224\n","num_classes = 10\n","epochs = 5\n","batch_size = 32 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HJSIPHPl1gV9"},"source":["# Path de dataset"]},{"cell_type":"code","metadata":{"id":"vP4R707H1gV-"},"source":["train_data_dir = 'dataset/train'  \n","validation_data_dir = 'dataset/valid'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cGMM9iWT1gV_"},"source":["# Generador de imágenes (entrenamiento y validación)"]},{"cell_type":"code","metadata":{"id":"kNC1XkWY1gWA"},"source":["train_datagen = ImageDataGenerator(  \n","    rotation_range=20,\n","    zoom_range=0.2,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False,\n","    preprocessing_function=preprocess_input)\n","\n","valid_datagen = ImageDataGenerator(    \n","    rotation_range=20,\n","    zoom_range=0.2,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False,\n","    preprocessing_function=preprocess_input)\n","\n","train_generator = train_datagen.flow_from_directory(  \n","    train_data_dir,\n","    target_size=(width_shape, height_shape),\n","    batch_size=batch_size,\n","    #save_to_dir='',\n","    class_mode='categorical')\n","\n","validation_generator = valid_datagen.flow_from_directory(  \n","    validation_data_dir,\n","    target_size=(width_shape, height_shape),\n","    batch_size=batch_size,\n","    #save_to_dir='',\n","    class_mode='categorical')\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CHHcuoff1gWC"},"source":["# Entrenamiento de modelo VGG16"]},{"cell_type":"code","metadata":{"id":"h7x0Y9c31gWC"},"source":["nb_train_samples = 1490\n","nb_validation_samples = 50\n","\n","image_input = Input(shape=(width_shape, height_shape, 3))\n","\n","model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n","\n","last_layer = model.get_layer('fc2').output\n","out = Dense(num_classes, activation='softmax', name='output')(last_layer)\n","custom_vgg_model = Model(image_input, out)\n","\n","for layer in custom_vgg_model.layers[:-1]:\n","\tlayer.trainable = False\n","    \n","\n","custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n","\n","custom_vgg_model.summary()\n","\n","model_history = custom_vgg_model.fit_generator(  \n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    steps_per_epoch=nb_train_samples//batch_size,\n","    validation_steps=nb_validation_samples//batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4v0BJEol1gWD"},"source":["# Grabar modelo en disco"]},{"cell_type":"code","metadata":{"id":"C_OMby0Z1gWE"},"source":["custom_vgg_model.save(\"models/model_VGG16.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15E5LVx91gWE"},"source":["# Gráficas de entrenamiento y validación (accuracy - loss)"]},{"cell_type":"code","metadata":{"id":"Fw8CxriV1gWF"},"source":["def plotTraining(hist, epochs, typeData):\n","    \n","    if typeData==\"loss\":\n","        plt.figure(1,figsize=(10,5))\n","        yc=hist.history['loss']\n","        xc=range(epochs)\n","        plt.ylabel('Loss', fontsize=24)\n","        plt.plot(xc,yc,'-r',label='Loss Training')\n","    if typeData==\"accuracy\":\n","        plt.figure(2,figsize=(10,5))\n","        yc=hist.history['accuracy']\n","        for i in range(0, len(yc)):\n","            yc[i]=100*yc[i]\n","        xc=range(epochs)\n","        plt.ylabel('Accuracy (%)', fontsize=24)\n","        plt.plot(xc,yc,'-r',label='Accuracy Training')\n","    if typeData==\"val_loss\":\n","        plt.figure(1,figsize=(10,5))\n","        yc=hist.history['val_loss']\n","        xc=range(epochs)\n","        plt.ylabel('Loss', fontsize=24)\n","        plt.plot(xc,yc,'--b',label='Loss Validate')\n","    if typeData==\"val_accuracy\":\n","        plt.figure(2,figsize=(10,5))\n","        yc=hist.history['val_accuracy']\n","        for i in range(0, len(yc)):\n","            yc[i]=100*yc[i]\n","        xc=range(epochs)\n","        plt.ylabel('Accuracy (%)', fontsize=24)\n","        plt.plot(xc,yc,'--b',label='Training Validate')\n","        \n","\n","    plt.rc('xtick',labelsize=24)\n","    plt.rc('ytick',labelsize=24)\n","    plt.rc('legend', fontsize=18) \n","    plt.legend()\n","    plt.xlabel('Number of Epochs',fontsize=24)\n","    plt.grid(True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzhOnKkK1gWG"},"source":["plotTraining(model_history,epochs,\"loss\")\n","plotTraining(model_history,epochs,\"accuracy\")\n","plotTraining(model_history,epochs,\"val_loss\")\n","plotTraining(model_history,epochs,\"val_accuracy\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZMhryju1gWH"},"source":["from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n","from keras.models import load_model\n","\n","names = ['AFRICAN FIREFINCH','ALBATROSS','ALEXANDRINE PARAKEET','AMERICAN AVOCET','AMERICAN BITTERN',\n","         'AMERICAN COOT','AMERICAN GOLDFINCH','AMERICAN KESTREL','AMERICAN PIPIT','AMERICAN REDSTART']\n","\n","modelt = load_model(\"models/model_VGG16.h5\")\n","#modelt = custom_vgg_model\n","\n","imaget_path = \"ImagenPrueba.jpg\"\n","imaget=cv2.resize(cv2.imread(imaget_path), (width_shape, height_shape), interpolation = cv2.INTER_AREA)\n","xt = np.asarray(imaget)\n","xt=preprocess_input(xt)\n","xt = np.expand_dims(xt,axis=0)\n","preds = modelt.predict(xt)\n","\n","print(names[np.argmax(preds)])\n","plt.imshow(cv2.cvtColor(np.asarray(imaget),cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0NVdBl21gWH"},"source":[""],"execution_count":null,"outputs":[]}]}